{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance & Risk Data\n",
    "\n",
    "In MongoDB, all data of a particular `fund` at a particular `date` is stored in a single document. Values are stored as an Embedded Document and can be nested further.\n",
    "\n",
    "```javascript\n",
    "{\n",
    "    _id: ObjectId('...')\n",
    "    date: 2023-12-31T00:00:00.000+00:00\n",
    "    fundId: ObjectId('...')\n",
    "    values: {\n",
    "        nav: 100\n",
    "        region: {\n",
    "            AMER: 0.3\n",
    "            APAC: 0.2\n",
    "            EMEA: 0.1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Import the libraries and connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "client = MongoClient(os.environ[\"MONGODB_HOST\"])\n",
    "db = client.ftkdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index is Timestamp, row is Series\n",
    "# values can be an empty dict\n",
    "def save_data(fund, data):\n",
    "    for date, row in data.iterrows():    \n",
    "        row.index = row.index.map(lambda x: f'values.{x}')\n",
    "        db.data.update_one({\n",
    "            'fundId': fund['_id'],\n",
    "            'date': date\n",
    "        },{\n",
    "            '$set': {**row.dropna().to_dict()}\n",
    "        },\n",
    "        upsert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('2023-12-31', periods=3, freq='M')\n",
    "navs = pd.DataFrame(np.random.randint(100, 110, size=3), index=dates, columns=['nav'])\n",
    "\n",
    "fund1 = db.fund.find_one({'name': 'Fund One'})\n",
    "fund2 = db.fund.find_one({'name': 'Fund Two'})\n",
    "fund3 = db.fund.find_one({'name': 'Fund Three'})\n",
    "fund4 = db.fund.find_one({'name': 'Fund Four'})\n",
    "\n",
    "save_data(fund1, navs)\n",
    "save_data(fund3, navs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period cannot be encoded\n",
    "rets = navs.pct_change().to_period()\n",
    "rets = rets.to_timestamp()\n",
    "rets.index = rets.index + pd.offsets.MonthEnd(0)\n",
    "rets.columns = ['return']\n",
    "\n",
    "save_data(fund2, rets)\n",
    "save_data(fund3, rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = pd.DataFrame(np.random.rand(3, 3), index=dates, columns=['region.AMER', 'region.EMEA', 'region.APAC'])\n",
    "save_data(fund1, regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = pd.concat([navs, rets, regions], axis=1)\n",
    "save_data(fund4, multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "1. Single fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(db.data.find({'fundId': fund1['_id']}).sort({'date': 1}))\n",
    "df = pd.DataFrame([d['values'] for d in data], index=[d['date'] for d in data])\n",
    "\n",
    "navs = df.loc[:, 'nav']\n",
    "regions = df.loc[:, 'region'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load data of all funds including fund name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "pipeline = [\n",
    "    {\n",
    "        '$match': {\n",
    "            'date': {\n",
    "                '$gte': datetime(2023, 12, 31, 0, 0, 0, tzinfo=timezone.utc)\n",
    "            }\n",
    "        }\n",
    "    }, {\n",
    "        '$lookup': {\n",
    "            'from': 'fund', \n",
    "            'localField': 'fundId', \n",
    "            'foreignField': '_id', \n",
    "            'as': 'fund'\n",
    "        }\n",
    "    }, {\n",
    "        '$unwind': {\n",
    "            'path': '$fund'\n",
    "        }\n",
    "    }, {\n",
    "        '$project': {\n",
    "            '_id': 0, \n",
    "            'date': 1, \n",
    "            'fundId': 1, \n",
    "            'fundName': '$fund.name', \n",
    "            'values': 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "raw = pd.json_normalize(db.data.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all risk data type, but lots of NaN\n",
    "sparse = raw.set_index(['fundId','fundName','date'])\n",
    "sparse.to_excel('sparse.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = raw.melt(id_vars=['date','fundId','fundName']).dropna().pivot(index=['fundId','fundName','variable'], columns='date')\n",
    "dense.columns = dense.columns.droplevel(0)\n",
    "dense.to_excel('dense.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse(data):\n",
    "    \"\"\"Preprocess for updating database\"\"\"\n",
    "    data.columns.name = 'date'\n",
    "    data = data.T.reset_index().melt(id_vars=['date']).pivot(index=['fundId','fundName','date'], columns='variable')\n",
    "    data.columns = data.columns.droplevel(0)\n",
    "    return data\n",
    "\n",
    "def to_dense(data):\n",
    "    data = data.reset_index().melt(id_vars=['date','fundId','fundName']).dropna().pivot(index=['fundId','fundName','variable'], columns='date')\n",
    "    data.columns = data.columns.droplevel(0)\n",
    "    return data\n",
    "\n",
    "def import_data(path):\n",
    "    data = pd.read_excel(path, index_col=[0,1,2])\n",
    "    if data.index.names == ['fundId', 'fundName', 'variable']:\n",
    "        # Convert dense format to sparse format\n",
    "        data = to_sparse(data)\n",
    "    if data.index.names == ['fundId', 'fundName', 'date']:\n",
    "        for index, row in data.iterrows():\n",
    "            fund_id = index[0]\n",
    "            date = index[2]\n",
    "            db.data.update_one({\n",
    "                'fundId': ObjectId(fund_id),\n",
    "                'date': date\n",
    "            },{\n",
    "                '$set': {**row.dropna().to_dict()}\n",
    "            },\n",
    "            upsert=True)            \n",
    "\n",
    "df1_dense = pd.read_excel('dense.xlsx', index_col=[0,1,2]).sort_index()\n",
    "df1_sparse = pd.read_excel('sparse.xlsx', index_col=[0,1,2]).sort_index()\n",
    "\n",
    "df2_dense = to_dense(df1_sparse).sort_index()\n",
    "df2_sparse = to_sparse(df1_dense).sort_index()\n",
    "\n",
    "pd.testing.assert_frame_equal(df1_dense, df2_dense)\n",
    "pd.testing.assert_frame_equal(df1_sparse, df2_sparse, check_names=False)\n",
    "\n",
    "import_data('dense.xlsx')\n",
    "import_data('sparse.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
